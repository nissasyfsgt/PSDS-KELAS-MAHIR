{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natural Language Processing (NPL) Dasar.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyORoKKE6XsS6tkCeX1batBt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nissasyfsgt/PSDS-KELAS-MAHIR/blob/main/Natural_Language_Processing_(NPL)_Dasar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKyUunQtR1Am"
      },
      "source": [
        "#**Natural Language Processing (NPL) Dasar**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83cMxteoS_bV"
      },
      "source": [
        "##**Pembuka**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtJi_78tR8x1"
      },
      "source": [
        "Assalamu'alaikum warahmatullahi wabarakatuh.\n",
        "\n",
        "Puji syukur kehadirat Allah Subhana Wata'ala atas limpahan Rahmat dan HidayahNya kepada kita semua.\n",
        "Sholawat serta salam senantiasa tercurah limpahkan kepada baginda Muhammad Rasulullah Salallahualaihiwassalam. \n",
        "\n",
        "Halo para Pejuang Data. Selamat berjumpa di pertemuan ketujuh Program Training Algoritma Machine Learning Kelas Mahir.\n",
        "\n",
        "Pada pertemuan ini kamu akan belajar:\n",
        "*   Apa itu NLP\n",
        "*   Scrapping Data\n",
        "*   Text Preprocessing\n",
        "     *   Case Folding & Data Cleaning\n",
        "     *   Lemmatisasi\n",
        "     *   Stemming\n",
        "     *   Slang Word\n",
        "     *   Stop Word\n",
        "     *   Unwanted Word\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdNiGYHkTCH1"
      },
      "source": [
        "##**Import Library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LzZqTxCRpO8"
      },
      "source": [
        "import sys\n",
        "\n",
        "if not sys.warnoptions:\n",
        "  import warnings\n",
        "  warnings.simplefilter(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or7vGogrTPvD"
      },
      "source": [
        "##**Natural Language Processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE7EqzGGTSv-"
      },
      "source": [
        "Natural Language Processing (NLP) merupakan salah satu cabang ilmu AI yang berfokus pada pengolahan\n",
        "bahasa natural. Bahasa natural adalah bahasa yang secara umum digunakan oleh manusia dalam\n",
        "berkomunikasi satu sama lain. Bahasa yang diterima oleh komputer butuh untuk diproses dan dipahami terlebih\n",
        "dahulu supaya maksud dari user bisa dipahami dengan baik oleh komputer.\n",
        "\n",
        "Ada berbagai terapan aplikasi dari NLP. Diantaranya adalah Chatbot (aplikasi yang membuat user bisa seolaholah\n",
        "melakukan komunikasi dengan computer), Stemming atau Lemmatization (pemotongan kata dalam\n",
        "bahasa tertentu menjadi bentuk dasar pengenalan fungsi setiap kata dalam kalimat), Summarization (ringkasan\n",
        "dari bacaan), Translation Tools (menterjemahkan bahasa) dan aplikasi-aplikasi lain yang memungkinkan\n",
        "komputer mampu memahami instruksi bahasa yang diinputkan oleh user.\n",
        "\n",
        "Pustejovsky dan Stubbs (2012) menjelaskan bahwa ada beberapa area utama penelitian pada field NLP,\n",
        "diantaranya:\n",
        "1. **Question Answering Systems (QAS).** Kemampuan komputer untuk menjawab pertanyaan yang\n",
        "diberikan oleh user. Daripada memasukkan keyword ke dalam browser pencarian, dengan QAS, user bisa\n",
        "langsung bertanya dalam bahasa natural yang digunakannya, baik itu Inggris, Mandarin, ataupun\n",
        "Indonesia.\n",
        "2. **Summarization.** Pembuatan ringkasan dari sekumpulan konten dokumen atau email. Dengan\n",
        "menggunakan aplikasi ini, user bisa dibantu untuk mengkonversikan dokumen teks yang besar ke dalam\n",
        "bentuk slide presentasi.\n",
        "Machine Translation. Produk yang dihasilkan adalah aplikasi yang dapat\n",
        "memahami bahasa manusia dan menterjemahkannya ke dalam bahasa lain. Termasuk di dalamnya adalah\n",
        "Google Translate yang apabila dicermati semakin membaik dalam penterjemahan bahasa. Contoh lain lagi\n",
        "adalah BabelFish yang menterjemahkan bahasa pada real time.\n",
        "3. **Speech Recognition.** Field ini merupakan cabang ilmu NLP yang cukup sulit. Proses pembangunan\n",
        "model untuk digunakan telpon/komputer dalam mengenali bahasa yang diucapkan sudah banyak\n",
        "dikerjakan. Bahasa yang sering digunakan adalah berupa pertanyaan dan perintah.\n",
        "4. **Document classification.** Sedangkan aplikasi ini adalah merupakan area penelitian NLP Yang paling\n",
        "sukses. Pekerjaan yang dilakukan aplikasi ini adalah menentukan dimana tempat terbaik dokumen yang\n",
        "baru diinputkan ke dalam sistem. Hal ini sangat berguna pada aplikasi spam filtering, news article\n",
        "classification, dan movie review."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28iBfzPqTzdt"
      },
      "source": [
        "##**Scrapping Data Text**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HfIgCzrT1yy"
      },
      "source": [
        "Sebelum melakukan penerapan dan berbagai penelitian. Mengumpulkan data teks sebagai bahan dasar dari\n",
        "bidang ini merupakan hal yang sangat penting. Proses ini biasa disebut dengan scrapping data. Aktivitas\n",
        "scrapping data bisa dilakukan melalui berbagai platfrom. Mulai langsung pada halaman web tertentu, melalui\n",
        "API seperti Twitter, atau melalui tools yang sudah disediakan, bisa free atau berbayar. Untuk mulai belajar NLP,\n",
        "kita akan menggunakan tools. Toolls/Library `google_play_scrapper` adalah library yang dapat digunakan\n",
        "untuk mengambil review dari google apps. Pertama kita perlu melakukan instalasi sebagai berikut."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSMTFK8nUEXX"
      },
      "source": [
        "**Instalasi google play scrapper**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKCZ2KjwUGLD",
        "outputId": "32d0d9de-e1e4-4e56-8ab7-c19793ec88cc"
      },
      "source": [
        "!pip install google_play_scraper"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google_play_scraper\n",
            "  Downloading google-play-scraper-1.0.2.tar.gz (52 kB)\n",
            "\u001b[?25l\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 10 kB 21.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 20 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 30 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 40 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 51 kB 3.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 52 kB 929 kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: google-play-scraper\n",
            "  Building wheel for google-play-scraper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-play-scraper: filename=google_play_scraper-1.0.2-py3-none-any.whl size=24393 sha256=2224b5a7b6c92cb9c4d2abbf54a72e62004391b736d2097576577b0cc057c1f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/99/eb/bbb9d24a5c526980647efc10336eaaeffcf07749f581111128\n",
            "Successfully built google-play-scraper\n",
            "Installing collected packages: google-play-scraper\n",
            "Successfully installed google-play-scraper-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHrYf3TVUL95"
      },
      "source": [
        "**Import Library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7NK3dTKUOPS"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google_play_scraper import Sort, reviews # Librray untuk scrapping data texta\n",
        "import re # Library untuk teks preprocessing"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNYslNqjUeCE"
      },
      "source": [
        "**Scrapping Data Review Teks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJGqRWS7UhBt"
      },
      "source": [
        "result, continuation_token = reviews(\n",
        "'com.whatsapp', # Alamat apps\n",
        "lang='id', # Bahasa Review , defaults : 'en'\n",
        "country='id', # Negara Asal Reviewer defaults : 'us'\n",
        "sort=Sort.MOST_RELEVANT, # Urutan Review yang diambil , defaults : MOST_RELEVANT\n",
        "count=1000, # Jumlah Review yang diambil, defaults : 100\n",
        "filter_score_with=None # Jumlah Bintang , default: None(means all score)\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0rOwP_jU7jx"
      },
      "source": [
        "**Menyimpan Hasil Review dalam DataFrame**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "g0Mfo36uVjcr",
        "outputId": "c86ca062-622e-4e29-be9f-a55ad4be5676"
      },
      "source": [
        "Hasil_Scrapping = pd.DataFrame(result)\n",
        "Hasil_Scrapping.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewId</th>\n",
              "      <th>userName</th>\n",
              "      <th>userImage</th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>reviewCreatedVersion</th>\n",
              "      <th>at</th>\n",
              "      <th>replyContent</th>\n",
              "      <th>repliedAt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gp:AOqpTOGFcvBuRG5mOK0MHsonwM1HHAtKavNwumDs_pd...</td>\n",
              "      <td>Rahman Danu</td>\n",
              "      <td>https://play-lh.googleusercontent.com/a/AATXAJ...</td>\n",
              "      <td>Keren banget apk nya,, pokoknya buat klean yan...</td>\n",
              "      <td>5</td>\n",
              "      <td>247</td>\n",
              "      <td>2.21.21.17</td>\n",
              "      <td>2021-11-01 08:09:50</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gp:AOqpTOGS1o5oYpUf68Bh-Jw0eD-vj5RHhQ3bPD6vtOX...</td>\n",
              "      <td>Ceng Aep</td>\n",
              "      <td>https://play-lh.googleusercontent.com/a/AATXAJ...</td>\n",
              "      <td>Bagus juga nihh !!!!!!!!! ;!!!!!!!!!!!!!!!!!!!...</td>\n",
              "      <td>3</td>\n",
              "      <td>175</td>\n",
              "      <td>2.21.20.20</td>\n",
              "      <td>2021-11-01 22:19:34</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gp:AOqpTOG7txMp2e7_Jd5YBAewHv0JlUDkfkek6SOGaP3...</td>\n",
              "      <td>Kayyisah Alfiyah hasanah</td>\n",
              "      <td>https://play-lh.googleusercontent.com/a/AATXAJ...</td>\n",
              "      <td>Bagus bangettttttt pokok nya keren deh!!!!!!!!...</td>\n",
              "      <td>5</td>\n",
              "      <td>17</td>\n",
              "      <td>2.21.20.20</td>\n",
              "      <td>2021-11-01 02:46:50</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gp:AOqpTOHZMzGKJRne6HyzA0AjpdwEEYBQni1wSsP2rYJ...</td>\n",
              "      <td>Anisa Manalu</td>\n",
              "      <td>https://play-lh.googleusercontent.com/a-/AOh14...</td>\n",
              "      <td>Aplikasi ini bagus banget!!!!!!!!!!!!!!!!!!!!!...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>2.21.21.17</td>\n",
              "      <td>2021-11-02 06:56:09</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gp:AOqpTOEyFdD1klHwt1CHwJFERU12PveZztlsglQBpbe...</td>\n",
              "      <td>Achella‚Ä¢Sakura</td>\n",
              "      <td>https://play-lh.googleusercontent.com/a-/AOh14...</td>\n",
              "      <td>Gem nya seru bange!!!!!!!!!!!!!!!!?!!!!!!!!!!!...</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2.21.21.17</td>\n",
              "      <td>2021-11-02 05:48:02</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            reviewId  ... repliedAt\n",
              "0  gp:AOqpTOGFcvBuRG5mOK0MHsonwM1HHAtKavNwumDs_pd...  ...      None\n",
              "1  gp:AOqpTOGS1o5oYpUf68Bh-Jw0eD-vj5RHhQ3bPD6vtOX...  ...      None\n",
              "2  gp:AOqpTOG7txMp2e7_Jd5YBAewHv0JlUDkfkek6SOGaP3...  ...      None\n",
              "3  gp:AOqpTOHZMzGKJRne6HyzA0AjpdwEEYBQni1wSsP2rYJ...  ...      None\n",
              "4  gp:AOqpTOEyFdD1klHwt1CHwJFERU12PveZztlsglQBpbe...  ...      None\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yNZzENSVobx"
      },
      "source": [
        "**Mengambil Series Data Teks Review**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd11i3BOVqFd",
        "outputId": "a29f49d0-5eaf-483a-b3be-f64f491bb34b"
      },
      "source": [
        "teks=Hasil_Scrapping.content\n",
        "teks"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      Keren banget apk nya,, pokoknya buat klean yan...\n",
              "1      Bagus juga nihh !!!!!!!!! ;!!!!!!!!!!!!!!!!!!!...\n",
              "2      Bagus bangettttttt pokok nya keren deh!!!!!!!!...\n",
              "3      Aplikasi ini bagus banget!!!!!!!!!!!!!!!!!!!!!...\n",
              "4      Gem nya seru bange!!!!!!!!!!!!!!!!?!!!!!!!!!!!...\n",
              "                             ...                        \n",
              "995    Aplikasi nya memang bagus tapi kenapa setiap s...\n",
              "996    Pokok nyo best kalian harus download ehh tapii...\n",
              "997    untuk chat,telepon,dan video call sangat jerni...\n",
              "998    ada bug dimana tidak bisa mengatur nada dering...\n",
              "999    Kenapa sih whatsApp saya di blokir terus!!!!!!...\n",
              "Name: content, Length: 1000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB9HJ7hbVvRt"
      },
      "source": [
        "##**Teks Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aBBXdaRVxXX"
      },
      "source": [
        "Setelah mendapat data teks. Salah satu tantangan dari data teks adalah bentuknya yang sangat beragam. Sebuah kata dapat ditulis dengan berbagai bentuk. Kemudian juga besar sekali kemungkinan adalah kesalahan penulisan. Tanda baca, angka, dan lain-lain. Oleh sebab itu, sebelum diolah lebih lanjut untuk diproses menjadi data numerik, maka diperlukan pemrosesan data teks agar menjadi bentuk yang lebih bersih dan standar. Yang akan sangat mempengaruhi hasil analisis data teks tersebut. Pada sentimen analisis misalnya, langkah ini menjadi sangat penting. Ada beberapa hal yang dilakukan pada tahap Teks Preprocessing:\n",
        "\n",
        "1. **Case Folding & Data Cleaning**\n",
        "Case folding adalah salah satu bentuk text preprocessing yang paling sederhana dan efektif meskipun sering diabaikan. Tujuan dari case folding untuk mengubah semua huruf dalam dokumen menjadi huruf kecil. Hanya huruf ‚Äòa‚Äô sampai ‚Äòz‚Äô yang diterima. Karakter selain huruf dihilangkan dan dianggap delimiter.\n",
        "\n",
        "Ada beberapa cara yang dapat digunakan dalam tahap case folding, diantaranya:\n",
        "\n",
        "*   Menghapus tanda baca\n",
        "*   Menghapus angka\n",
        "*   Mengubah text menjadi lowercase\n",
        "*   Menghapus whitepace (karakter kosong)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "M4pDbbnDWL_o",
        "outputId": "6d58b056-f2ba-48c8-8929-6ff43ded0937"
      },
      "source": [
        "# Menghapus tanda baca\n",
        "print(teks[11])\n",
        "teks[11]=re.sub(r'[^\\w]|_',' ', teks[11])\n",
        "teks[11]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aplikasi ini sangat jelek!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Makanya aku kasih bintang satu karena jelek!!!!!!!!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Aplikasi ini sangat jelek                                                                                                                                                                  Makanya aku kasih bintang satu karena jelek         '"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "xmzibpwjWXaI",
        "outputId": "94640122-b6f4-4431-9499-be531f51bf9f"
      },
      "source": [
        "# Menghapus angka\n",
        "print(teks[11])\n",
        "teks[11] = re.sub(\"\\S*\\d\\S*\", \"\", teks[11]).strip()\n",
        "teks[11] = re.sub(r\"\\b\\d+\\b\", \" \", teks[11])\n",
        "teks[11]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aplikasi ini sangat jelek                                                                                                                                                                  Makanya aku kasih bintang satu karena jelek         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Aplikasi ini sangat jelek                                                                                                                                                                  Makanya aku kasih bintang satu karena jelek'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "5H3wJMWvWb-X",
        "outputId": "37bcd2e9-7f8f-4e20-d647-457344c8493a"
      },
      "source": [
        "#Mengubah text menjadi lowercase\n",
        "print(teks[11])\n",
        "\n",
        "teks[11]=teks[11].lower()\n",
        "teks[11]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aplikasi ini sangat jelek                                                                                                                                                                  Makanya aku kasih bintang satu karena jelek\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'aplikasi ini sangat jelek                                                                                                                                                                  makanya aku kasih bintang satu karena jelek'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "yAjmya-PWg1s",
        "outputId": "ff8e9c49-2343-41d0-a66e-e872cb4723f1"
      },
      "source": [
        "# Menghapus white space\n",
        "print(teks[11])\n",
        "\n",
        "teks[11]=re.sub('[\\s]+', ' ', teks[11])\n",
        "teks[11]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aplikasi ini sangat jelek                                                                                                                                                                  makanya aku kasih bintang satu karena jelek\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'aplikasi ini sangat jelek makanya aku kasih bintang satu karena jelek'"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FusPyR6iWk69"
      },
      "source": [
        "Membuat Fungsi untuk Melakukan Case Folding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvoKEQizWozi"
      },
      "source": [
        "import re, string, unicodedata \n",
        "def Case_Folding(text):\n",
        "    # Hapus non-ascii\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    \n",
        "    # Menghapus Tanda Baca\n",
        "    text = re.sub(r'[^\\w]|_',' ', text)\n",
        "    \n",
        "    # Menghapus Angka\n",
        "    text = re.sub(\"\\S*\\d\\S*\", \"\", text).strip()\n",
        "    text = re.sub(r\"\\b\\d+\\b\", \" \", text)\n",
        "    \n",
        "    # Mengubah text menjadi lowercase\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Menghapus white space\n",
        "    text = re.sub('[\\s]+', ' ', text)\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKFwEnSxWz7D"
      },
      "source": [
        "##**Lemmatization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM32DznSW4sY"
      },
      "source": [
        "Proses pengurangan berbagai bentuk kata yang berubah menjadi satu bentuk untuk memudahkan analisis. e.g. kata dari ‚Äúswim‚Äù, ‚Äúswimming‚Äù, ‚Äúswims‚Äù, ‚Äúswam‚Äù, adalah semua bentuk dari ‚Äúswim‚Äù. Nah jadi lemma dari semua kata-kata tersebut adalah ‚Äúswim‚Äù.\n",
        "\n",
        "Untuk data teks berbahasa Indonesia, kita akan menggunakan library `nlp-id`. Pertama kita harus menginstallnya terlebih dahulu.\n",
        "\n",
        "    !pip install nlp-id"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbEQUZUjXBTS",
        "outputId": "b744d4c5-52a6-4f04-f940-5835842b93d3"
      },
      "source": [
        "!pip install nlp-id"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nlp-id\n",
            "  Downloading nlp_id-0.1.12.0.tar.gz (7.9 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.9 MB 2.8 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22\n",
            "  Downloading scikit_learn-0.22-cp37-cp37m-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.0 MB 23.8 MB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.5 MB 30.9 MB/s \n",
            "\u001b[?25hCollecting wget==3.2\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4.5->nlp-id) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22->nlp-id) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22->nlp-id) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22->nlp-id) (1.0.1)\n",
            "Building wheels for collected packages: nlp-id, nltk, wget\n",
            "  Building wheel for nlp-id (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nlp-id: filename=nlp_id-0.1.12.0-py3-none-any.whl size=8074105 sha256=a2d02c73f9f4fff8b1020831c6035e090b1911aaf7eeefcaa7fb9f103e90b8b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/50/48/da59531125bd94f48dfe66140f41d8fd8a4f04062050375013\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449921 sha256=b11b0e3db127f912f460ee5df6d4128b3a31024e349310598d82c71177ee9c95\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=1dfe228a63a4bba98e7e53b075c19523712b5c545846b1b09c53c36c4aa14253\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built nlp-id nltk wget\n",
            "Installing collected packages: wget, scikit-learn, nltk, nlp-id\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nlp-id-0.1.12.0 nltk-3.4.5 scikit-learn-0.22 wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M28mxKoRXG_X"
      },
      "source": [
        "Kemudian kita akan menggunakan fungsi Lemmatizer() untuk melakukan lemmatisasi data teks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "CugDjz_PXIut",
        "outputId": "eeb6b6ee-014b-4b75-92c8-bafa3d411c9c"
      },
      "source": [
        "from nlp_id.lemmatizer import Lemmatizer \n",
        "lemmatizer = Lemmatizer() \n",
        "print(teks[11])\n",
        "teks[11]=lemmatizer.lemmatize(teks[11]) \n",
        "teks[11]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aplikasi ini sangat jelek makanya aku kasih bintang satu karena jelek\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'aplikasi ini sangat jelek makanya aku kasih bintang satu karena jelek'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDuE23hdXQEj"
      },
      "source": [
        "##**Stemming**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi31cU7rXUpP"
      },
      "source": [
        "Stemming merupakan suatu proses untuk menemukan kata dasar dari sebuah kata. Dengan menghilangkan semua imbuhan (affixes) baik yang terdiri dari awalan (prefixes), sisipan (infixes), akhiran (suffixes) dan confixes (kombinasi dari awalan dan akhiran) pada kata turunan. Stemming digunakan untuk mengganti bentuk dari suatu kata menjadi kata dasar dari kata tersebut yang sesuai dengan struktur morfologi Bahasa Indonesia yang baik dan benar.\n",
        "\n",
        "Untuk data teks berbahasa Indonesia, kita akan menggunakan library `PySastrawi`. Pertama kita harus menginstallnya terlebih dahulu.\n",
        "\n",
        "    !pip install PySastrawi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSHFbmVAXay3",
        "outputId": "1dd0f3d3-5953-49d0-8ec0-730033584349"
      },
      "source": [
        "!pip install PySastrawi"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PySastrawi\n",
            "  Downloading PySastrawi-1.2.0-py2.py3-none-any.whl (210 kB)\n",
            "\u001b[?25l\r\u001b[K     |‚ñà‚ñã                              | 10 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñè                            | 20 kB 16.9 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñä                           | 30 kB 21.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 40 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 51 kB 3.9 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 61 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 71 kB 3.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 81 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 92 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 102 kB 3.4 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 112 kB 3.4 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä             | 122 kB 3.4 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 133 kB 3.4 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 143 kB 3.4 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 153 kB 3.4 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 163 kB 3.4 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 174 kB 3.4 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 184 kB 3.4 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 194 kB 3.4 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 204 kB 3.4 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 210 kB 3.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: PySastrawi\n",
            "Successfully installed PySastrawi-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "QOBPouw6XeqU",
        "outputId": "d9c9b599-f9df-4f50-bf6f-6eb9cf36b3af"
      },
      "source": [
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "# Membuat stemmer\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "print(teks[12])\n",
        "\n",
        "teks[12] = stemmer.stem(teks[12])\n",
        "teks[12]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maaf Saya kasiih 3 rating dulu karena saya ingin mengirim foto tetapi tidak bisa dan ada tulisan seperti ini \"pengunduhan gagal\" dan seperti ini \"pengunduhan tidak dapat di selesaikan silahkan coba lagi nanti\" tolong ya ini lagi update atau memang hp saya? Soalnya saya check ulasan lain ada yang seperti saya juga, tapi kalau chat orang bisa tapi knp kalo kirim foto/vn ga bisa ya? Wa busness saya juga sudah di hapus tapi tetap saja tolong ya di perbaiki üòáüôè\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'maaf saya kasiih 3 rating dulu karena saya ingin kirim foto tetapi tidak bisa dan ada tulis seperti ini unduh gagal dan seperti ini unduh tidak dapat di selesai silah coba lagi nanti tolong ya ini lagi update atau memang hp saya soal saya check ulas lain ada yang seperti saya juga tapi kalau chat orang bisa tapi knp kalo kirim foto vn ga bisa ya wa busness saya juga sudah di hapus tapi tetap saja tolong ya di baik'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvSOkVrSXik2"
      },
      "source": [
        "##**Slang Words**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0DSnHqeXmN_"
      },
      "source": [
        "Slang adalah kata-kata yang tidak baku secara bahasa namun sering dipakai oleh pengguna bahasa. Kita perlu melakukan standarisasi untuk slang."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEb8PewqXo7r"
      },
      "source": [
        "slang_dictionary = pd.read_csv('https://raw.githubusercontent.com/nikovs/data-science-portfolio/master/topic%20modelling/colloquial-indonesian-lexicon.csv')\n",
        "slang_dict = pd.Series(slang_dictionary['formal'].values,index=slang_dictionary['slang']).to_dict()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4ahu7n0X1ma"
      },
      "source": [
        "def Slangwords(text):\n",
        "    for word in text.split():\n",
        "        if word in slang_dict.keys():\n",
        "            text = text.replace(word, slang_dict[word])\n",
        "    return text"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "x1bhmPtmX4YB",
        "outputId": "2d58c7b1-9ad1-4821-80aa-da3aa37d833f"
      },
      "source": [
        "print(teks[0])\n",
        "\n",
        "teks[0]=Slangwords(teks[0]) \n",
        "teks[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keren banget apk nya,, pokoknya buat klean yang blm download di wajibkan untuk mendownload apk ini soalnya apk nya bagus banget!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!keren dah pokoknya!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!g udah liat kebawah g dpt bansos jgaüóø\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Keren banenggaket apk nya,, pokoknya buat klean yanenggak belum download di wajibkan untuk mendownload apk ini soalnya apk nya baenggakus banenggaket!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!keren deh pokoknya!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!enggak udeh lihat kebawah enggak dapat bansos jenggakaüóø'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rhRwtHZX8r2"
      },
      "source": [
        "##**Stopword**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jepi7Ym6X_jS"
      },
      "source": [
        "Stop words adalah kata umum (common words) yang biasanya muncul dalam jumlah besar dan dianggap tidak memiliki makna. Stop words umumnya dimanfaatkan dalam task information retrieval, termasuk oleh Google (penjelasannya di sini). Contoh stop words untuk bahasa Inggris diantaranya ‚Äúof‚Äù, ‚Äúthe‚Äù. Sedangkan untuk bahasa Indonesia diantaranya ‚Äúyang‚Äù, ‚Äúdi‚Äù, ‚Äúke‚Äù."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjpNwnN7YB8a"
      },
      "source": [
        "from nlp_id.stopword import StopWord \n",
        "stopword = StopWord()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "rAyv2rT_YEPL",
        "outputId": "3afcfbb0-28c0-41db-f58a-ac30571c4a27"
      },
      "source": [
        "from nlp_id.stopword import StopWord \n",
        "print(teks[11])\n",
        "\n",
        "teks[11]=stopword.remove_stopword(teks[11])\n",
        "teks[11]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aplikasi ini sangat jelek makanya aku kasih bintang satu karena jelek\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'aplikasi jelek kasih bintang jelek'"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WosBEdiYIzo"
      },
      "source": [
        "##**Unwanted Words**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-fdvJcKYL8z"
      },
      "source": [
        "Unwanted words adalah kata-kata yang berada di luar beberapa hal di atas namun perlu untuk kita hapus. Kita bisa mendefinisikan sendiri kata-kata atau karakter yang ingin kita hilangkan dari data teks yang kita peroleh."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IySBzxomYYqp"
      },
      "source": [
        "unwanted_words = ['sy', 'karna', 'gue', 'pun', 'nya', 'yg', 'gw', 'ke', 'gak', 'ga', 'buat', 'selama', 'akan', 'gua', 'gw', \n",
        "                 'gue', 'dampak', 'tau', 'banget', 'mohon', 'dii', 'kalo', 'dll', 'kadang', 'ya', 'coba', 'langsung',\n",
        "                 'cuman', 'cuma', 'biar', 'an', 'kayak', 'dar', 'bikin', 'ssaja', 'sih', 'si', 'situ', 'e', 'utk', 'pake',\n",
        "                 'diin', 'serba', 'ampun', 'untuj', 'deh', 'jd', 'ku', 'total', 'lg', 'arti', 'terimakasih','and', 'udah',\n",
        "                 'kali', 'dasar', 'tiada', 'indonesia', 'pas', 'tidiak', 'the', 'http', 'co', 'com', 'di', 'https', 'kak',\n",
        "                 'dr', 'aja', 'klo', 'tp', 'gitu', 'udh', 'min', 'halo', 'tidak', 'bisa', 'sudah', 'yg', 'apa', 'malah',\n",
        "                 'masih', 'mau', 'kok', 'belum', 'buat', 'atau', 'sama', 'gak', 'ga', 'udah', 'banyak', 'selalu', 'masuk',\n",
        "                 'atau', 'belum', 'ini', 'tp', 'ke', 'ya', 'itu', 'aja', 'saja', 'juga', 'aplikasi', 'my pertamina',\n",
        "                 'mypertamina', 'maaf', 'gk', 'tdk', 'trus', 'jg', 'nih', 'sdh', 'mulu', 'padahal', 'kenapa', 'gimana',\n",
        "                 'gmn', 'sih', 'bs', 'suruh', 'tolong', 'dah', 'bagus', 'my', 'pertamina', 'jadi', 'kalau', 'engenggakk',\n",
        "                 'engenggak', 'pakai', 'bilang', 'mending', 'hasil', 'orang', 'muncul', 'ssudah', 'kasih', 'mala', 'malah']"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxPtoJ3MYcHY",
        "outputId": "724c135b-d238-47b6-af93-d87a2e711d92"
      },
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "def RemoveUnwantedwords(text):\n",
        "    word_tokens = word_tokenize(text)\n",
        "    filtered_sentence = [word for word in word_tokens if not word in unwanted_words]\n",
        "    return ' '.join(filtered_sentence)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "mo17x2nqYgVW",
        "outputId": "384d3d9c-478c-4c45-e04c-696c15cb9a2b"
      },
      "source": [
        "print(teks[0])\n",
        "\n",
        "teks[0]=RemoveUnwantedwords(teks[0])\n",
        "teks[0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keren banenggaket apk nya,, pokoknya buat klean yanenggak belum download di wajibkan untuk mendownload apk ini soalnya apk nya baenggakus banenggaket!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!keren deh pokoknya!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!enggak udeh lihat kebawah enggak dapat bansos jenggakaüóø\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Keren banenggaket apk , , pokoknya klean yanenggak download wajibkan untuk mendownload apk soalnya apk baenggakus banenggaket ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! keren pokoknya ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! enggak udeh lihat kebawah enggak dapat bansos jenggakaüóø'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZxNpKqoYktX"
      },
      "source": [
        "##**Menerapkan Semua Langkah**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6528UD-hYn46",
        "outputId": "76a3ce05-2bac-48c8-f1e7-f32e3b6bef77"
      },
      "source": [
        "Hasil_Scrapping['content_processed'] = ''\n",
        "\n",
        "for i, row in Hasil_Scrapping.iterrows():\n",
        "    content = Hasil_Scrapping.content[i]\n",
        "    result = Case_Folding(content)\n",
        "    result = lemmatizer.lemmatize(result)\n",
        "    result = stemmer.stem(result)\n",
        "    result = Slangwords(result)\n",
        "    result = stopword.remove_stopword(result)\n",
        "    result = RemoveUnwantedwords(result)\n",
        "    Hasil_Scrapping['content_processed'][i] = result"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "-S-W_-UZYsPl",
        "outputId": "bb6d4448-b91a-4ab4-9831-54bfd46133cb"
      },
      "source": [
        "Hasil_Scrapping[['content', 'content_processed']]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>content_processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Keren banenggaket apk , , pokoknya klean yanen...</td>\n",
              "      <td>keren banenggaket apk pokok klean yanenggak do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bagus juga nihh !!!!!!!!! ;!!!!!!!!!!!!!!!!!!!...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bagus bangettttttt pokok nya keren deh!!!!!!!!...</td>\n",
              "      <td>pokok keren</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aplikasi ini bagus banget!!!!!!!!!!!!!!!!!!!!!...</td>\n",
              "      <td>lihat lihat enggak</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gem nya seru bange!!!!!!!!!!!!!!!!?!!!!!!!!!!!...</td>\n",
              "      <td>gem seru bange bohong hanyukk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>Aplikasi nya memang bagus tapi kenapa setiap s...</td>\n",
              "      <td>tekan vn voice note teman hp mati tokonh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Pokok nyo best kalian harus download ehh tapii...</td>\n",
              "      <td>pokok best download eh mod kirim pesan mama pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>untuk chat,telepon,dan video call sangat jerni...</td>\n",
              "      <td>chat telepon video call jernih status video fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>ada bug dimana tidak bisa mengatur nada dering...</td>\n",
              "      <td>bug atur nada dering kostum wa atur nada derin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Kenapa sih whatsApp saya di blokir terus!!!!!!...</td>\n",
              "      <td>whatsapp blokir marah marah whetsapp</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               content                                  content_processed\n",
              "0    Keren banenggaket apk , , pokoknya klean yanen...  keren banenggaket apk pokok klean yanenggak do...\n",
              "1    Bagus juga nihh !!!!!!!!! ;!!!!!!!!!!!!!!!!!!!...                                                   \n",
              "2    Bagus bangettttttt pokok nya keren deh!!!!!!!!...                                        pokok keren\n",
              "3    Aplikasi ini bagus banget!!!!!!!!!!!!!!!!!!!!!...                                 lihat lihat enggak\n",
              "4    Gem nya seru bange!!!!!!!!!!!!!!!!?!!!!!!!!!!!...                      gem seru bange bohong hanyukk\n",
              "..                                                 ...                                                ...\n",
              "995  Aplikasi nya memang bagus tapi kenapa setiap s...           tekan vn voice note teman hp mati tokonh\n",
              "996  Pokok nyo best kalian harus download ehh tapii...  pokok best download eh mod kirim pesan mama pa...\n",
              "997  untuk chat,telepon,dan video call sangat jerni...  chat telepon video call jernih status video fo...\n",
              "998  ada bug dimana tidak bisa mengatur nada dering...  bug atur nada dering kostum wa atur nada derin...\n",
              "999  Kenapa sih whatsApp saya di blokir terus!!!!!!...               whatsapp blokir marah marah whetsapp\n",
              "\n",
              "[1000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}